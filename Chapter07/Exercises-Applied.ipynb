{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from matplotlib.pyplot import subplots\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (\n",
    "    ModelSpec as MS,\n",
    "    summarize,\n",
    ")\n",
    "from ISLP import confusion_table\n",
    "from ISLP.models import contrast\n",
    "\n",
    "from sklearn.discriminant_analysis import (\n",
    "    LinearDiscriminantAnalysis as qda,\n",
    "    QuadraticDiscriminantAnalysis as QDA,\n",
    ")\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data('Weekly')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(\n",
    "    (\n",
    "        df\n",
    "        .drop(columns=[\"Year\", \"Direction\"])\n",
    "        .corr()\n",
    "        .replace(to_replace=1, value=np.nan)\n",
    "    ),\n",
    "    title=\"Weekly Correlation\",\n",
    "    height=600,\n",
    "    text_auto=\".2f\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(\n",
    "    df,\n",
    "    y=[\"Lag1\", \"Lag2\", \"Lag3\", \"Lag4\", \"Lag5\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(\n",
    "    df,\n",
    "    x=[\"Lag1\", \"Lag2\", \"Lag3\", \"Lag4\", \"Lag5\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(\n",
    "    df,\n",
    "    x=[\"Lag1\", \"Lag2\", \"Lag3\", \"Lag4\", \"Lag5\"],\n",
    "    facet_col=\"Direction\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(\n",
    "    df,\n",
    "    y=\"Volume\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(\n",
    "    df,\n",
    "    x=\"Volume\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [\"Lag1\", \"Lag2\", \"Lag3\", \"Lag4\", \"Lag5\", \"Volume\"]\n",
    "response = \"Direction\"\n",
    "\n",
    "design = MS(df[predictors])\n",
    "X = design.fit_transform(df)\n",
    "y = df[response] == 'Up'\n",
    "\n",
    "model = sm.Logit(endog=y, exog=X)\n",
    "results = model.fit()\n",
    "summarize(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = results.predict()\n",
    "print(f\"{probabilities[:10]=}\")\n",
    "\n",
    "predictions = np.where(probabilities > 0.5, \"Up\", \"Down\")\n",
    "print(f\"{predictions[:10]=}\")\n",
    "\n",
    "px.imshow(confusion_table(predictions, df[response]), text_auto=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = df[\"Year\"] < 2009\n",
    "test_mask = ~train_mask\n",
    "\n",
    "print(f\"{train_mask.sum()=}, {test_mask.sum()=}\")\n",
    "\n",
    "X_train = X[train_mask]\n",
    "X_test = X[test_mask]\n",
    "\n",
    "y_train = y[train_mask]\n",
    "y_test = y[test_mask]\n",
    "\n",
    "lag_2_predictor = \"Lag2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_2_model = sm.Logit(endog=y_train, exog=X_train[[\"intercept\", lag_2_predictor]])\n",
    "lag_2_results = lag_2_model.fit()\n",
    "summarize(lag_2_results)\n",
    "\n",
    "lag_2_probabilities = lag_2_results.predict(X_test[[\"intercept\", lag_2_predictor]])\n",
    "print(f\"{lag_2_probabilities[:10]=}\")\n",
    "\n",
    "lag_2_predictions = np.where(lag_2_probabilities > 0.5, \"Up\", \"Down\")\n",
    "print(f\"{lag_2_predictions[:10]=}\")\n",
    "\n",
    "px.imshow(confusion_table(lag_2_predictions, df.loc[test_mask, response]), text_auto=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA(store_covariance=True)\n",
    "\n",
    "lda.fit(y=y_train, X=X_train[[lag_2_predictor]])\n",
    "print(f\"\"\"\n",
    "{lda.means_=\n",
    "}\n",
    "\n",
    "{lda.classes_=\n",
    "}\n",
    "\n",
    "{lda.priors_=\n",
    "}\n",
    "\n",
    "{lda.scalings_=\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "lda_probabilities = lda.predict(X_test[[lag_2_predictor]])\n",
    "print(f\"{lda_probabilities[:10]=}\")\n",
    "\n",
    "lda_predictions = np.where(lda_probabilities > 0.5, \"Up\", \"Down\")\n",
    "print(f\"{lda_predictions[:10]=}\")\n",
    "\n",
    "px.imshow(confusion_table(lda_predictions, df.loc[test_mask, response]), text_auto=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda = QDA(store_covariance=True)\n",
    "\n",
    "qda.fit(y=y_train, X=X_train[[lag_2_predictor]])\n",
    "print(f\"\"\"\n",
    "{qda.means_=\n",
    "}\n",
    "\n",
    "{qda.classes_=\n",
    "}\n",
    "\n",
    "{qda.priors_=\n",
    "}\n",
    "\n",
    "{qda.scalings_=\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "qda_probabilities = qda.predict(X_test[[lag_2_predictor]])\n",
    "print(f\"{qda_probabilities[:10]=}\")\n",
    "\n",
    "qda_predictions = np.where(qda_probabilities > 0.5, \"Up\", \"Down\")\n",
    "print(f\"{qda_predictions[:10]=}\")\n",
    "\n",
    "px.imshow(confusion_table(qda_predictions, df.loc[test_mask, response]), text_auto=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn.fit(y=y_train, X=X_train[[lag_2_predictor]])\n",
    "\n",
    "knn_probabilities = knn.predict(X_test[[lag_2_predictor]])\n",
    "print(f\"{knn_probabilities[:10]=}\")\n",
    "\n",
    "knn_predictions = np.where(knn_probabilities > 0.5, \"Up\", \"Down\")\n",
    "print(f\"{knn_predictions[:10]=}\")\n",
    "\n",
    "px.imshow(confusion_table(knn_predictions, df.loc[test_mask, response]), text_auto=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "\n",
    "nb.fit(y=y_train, X=X_train[[lag_2_predictor]])\n",
    "print(f\"\"\"\n",
    "{nb.class_prior_=\n",
    "}\n",
    "\n",
    "{nb.classes_=\n",
    "}\n",
    "\n",
    "{nb.theta_=\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "nb_probabilities = nb.predict(X_test[[lag_2_predictor]])\n",
    "print(f\"{nb_probabilities[:10]=}\")\n",
    "\n",
    "nb_predictions = np.where(nb_probabilities > 0.5, \"Up\", \"Down\")\n",
    "print(f\"{nb_predictions[:10]=}\")\n",
    "\n",
    "px.imshow(confusion_table(nb_predictions, df.loc[test_mask, response]), text_auto=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "islp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
